# ì°¸ê³  ë¸”ë¡œê·¸ url
# - streamlit ë°°í¬ : https://m.blog.naver.com/weisoon/223196954589
# - langchain : https://teddylee777.github.io/langchain/langchain-tutorial-03/ , https://rfriend.tistory.com/839
# - embedding, RAG : https://wikidocs.net/231600 ,https://wikidocs.net/233817, https://teddylee777.github.io/langchain/rag-tutorial/#%EB%8B%A8%EA%B3%84--retriever-%EC%83%9D%EC%84%B1


# python ver : 3.11.2 64bit
# vscì—ì„œ localí™˜ê²½ì— app ì‹¤í–‰í•˜ë ¤ë©´ ì»¤ë§¨ë“œì°½ì— {streamlit run main.py} ì…ë ¥

# í™˜ê²½ë³€ìˆ˜(githubì— ì˜¬ë¦´ë•ŒëŠ” ì£¼ì„ ì²˜ë¦¬í•œë‹¤.)
# from dotenv import load_dotenv
# load_dotenv()


# ëª¨ë“  ê²½ê³  ë©”ì‹œì§€ë¥¼ ë¬´ì‹œí•˜ë„ë¡ ì„¤ì •
import warnings
warnings.filterwarnings('ignore')

# streamlit
import streamlit as st

# langchain
from langchain import hub
from langchain_openai import OpenAIEmbeddings

# document loaders
from langchain_community.document_loaders import WebBaseLoader
from langchain.document_loaders import PyPDFLoader
from langchain_community.document_loaders.csv_loader import CSVLoader
from langchain_community.document_loaders import TextLoader

# text split
from langchain.text_splitter import RecursiveCharacterTextSplitter

# embedding
from langchain_community.embeddings import HuggingFaceEmbeddings, HuggingFaceBgeEmbeddings # ë¬´ë£Œ Open Source ê¸°ë°˜ ì„ë² ë”©


# vectorstores
from langchain_community.vectorstores import Chroma, FAISS
from langchain_community.vectorstores.utils import DistanceStrategy

# outputparser
from langchain_core.output_parsers import StrOutputParser

from langchain_core.runnables import RunnablePassthrough


# langchain message, Template
from langchain.schema import AIMessage, HumanMessage, SystemMessage
from langchain.prompts import ChatPromptTemplate

# ChatOpenAI
from langchain.chat_models import ChatOpenAI

# RAG ìƒì„±
# 1. txt ë¡œë“œ
@st.cache_data
def get_data():
    loader = TextLoader("240503_KBìºí”¼íƒˆ ìƒí’ˆì •ë³´.txt", encoding = 'utf-8')
    docs = loader.load()
    print(f"ë¬¸ì„œì˜ ìˆ˜: {len(docs)}")

    return docs

# get_data() í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ì—¬ docs ë³€ìˆ˜ ì •ì˜
docs = get_data()


# 2. split documents
@st.cache_data(hash_funcs={list : lambda _: None}) # ì–´ë–¤ ë¦¬ìŠ¤íŠ¸ê°€ ë“¤ì–´ì˜¤ë”ë¼ë„ í•´ì‹œ ê°’ì„ Noneìœ¼ë¡œ ì„¤ì •í•˜ì—¬ í•´ë‹¹ ì¸ìë¥¼ ìºì‹±ì—ì„œ ì œì™¸
def split_documents(docs):
    recursive_text_splitter = RecursiveCharacterTextSplitter(
        # ì‘ì€ ì²­í¬ í¬ê¸°ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.
        chunk_size=400,
        chunk_overlap=100,
        length_function=len,
        is_separator_regex=False,
    )
    split_docs = recursive_text_splitter.split_documents(docs)
    print(f"ë‚˜ëˆ„ì–´ì§„ ë¬¸ì„œì˜ ìˆ˜: {len(split_docs)}")
    print('\nsplit docs ì‚´í´ë³´ê¸°')
    for i in range(len(split_docs)) :
        print(split_docs[i],'\n')
    
    return split_docs


# ë¬¸ì„œë¥¼ ì²˜ë¦¬í•˜ì—¬ split_docs ë³€ìˆ˜ì— í• ë‹¹
split_docs = split_documents(docs)

# 3. ì„ë² ë”© ê°ì²´ ìƒì„±
@st.cache_resource
def load_embedding_model() :
    model = HuggingFaceEmbeddings(
        model_name='jhgan/ko-sbert-nli', # ì‚¬ì „í•™ìŠµ ì„ë² ë”© ëª¨ë¸
        model_kwargs={'device':'cpu'},
        encode_kwargs={'normalize_embeddings':True}, # ì„ë² ë”© ì •ê·œí™”í•˜ì—¬, ëª¨ë“  ë²¡í„°ê°€ ê°™ì€ ë²”ìœ„ì˜ ê°’ì„ ê°–ë„ë¡ í•¨
        )
    return model

embeddings_model = load_embedding_model()

# 4. ë²¡í„°ìŠ¤í† ì–´ ìƒì„±
vectorstore = FAISS.from_documents(
    documents=split_docs, embedding=embeddings_model,
    distance_strategy = DistanceStrategy.COSINE # ì½”ì‚¬ì¸ìœ ì‚¬ë„ë¡œ ì¸¡ì •
)

# 5. Retriever ìƒì„±
retriever = vectorstore.as_retriever(search_kwargs={'k':1}) # ë‹¨ì¼ ë¬¸ì„œ ê²€ìƒ‰


st.image('kbc_logo.png')

# ë§ˆì¼€íŒ… ë¬¸êµ¬ ìƒì„± í˜ì´ì§€ í™”ë©´ êµ¬ì„±
st.title('ìƒì„±í˜• AIë¥¼ í™œìš©í•œ ë§ˆì¼€íŒ… ë¬¸êµ¬ ìƒì„±')
st.text('\n')
# selectboxí˜•ì‹ ì˜ˆì‹œ
# opt_prod = st.selectbox('STEP1. ë¬¸êµ¬ë¥¼ ì‘ì„±í•˜ë ¤ëŠ” ëŒ€ì¶œ ìƒí’ˆì„ ì„ íƒí•´ì£¼ì„¸ìš”',
#     ['ì‹ ìš©ëŒ€ì¶œ','í¬ë¡œìŠ¤ì…€', 'ìë™ì°¨ ë‹´ë³´ ëŒ€ì¶œ', 'ì¤‘ê³ ì°¨ ëŒ€ì¶œ', 'ì‹ ì°¨ ëŒ€ì¶œ'])


opt_prod = st.radio(
    # r'''$\textsf{\large âœ… STEP1. ë¬¸êµ¬ë¥¼ ìƒì„±í•˜ë ¤ëŠ” ëŒ€ì¶œ ìƒí’ˆì„ ì„ íƒí•´ì£¼ì„¸ìš”}$''',['ì‹ ìš©ëŒ€ì¶œ','í¬ë¡œìŠ¤ì…€', 'ìë™ì°¨ ë‹´ë³´ ëŒ€ì¶œ', 'ì¤‘ê³ ì°¨ ëŒ€ì¶œ', 'ì‹ ì°¨ ëŒ€ì¶œ'], horizontal=True)
    r'''$\textsf{\large âœ… STEP1. ë¬¸êµ¬ë¥¼ ìƒì„±í•˜ë ¤ëŠ” ëŒ€ì¶œ ìƒí’ˆì„ ì„ íƒí•´ì£¼ì„¸ìš”}$''',['ë‚´ì¼ë¡œ ì‹ ìš©ëŒ€ì¶œ','ë‚´ì§‘ìœ¼ë¡œ ì‹ ìš©ëŒ€ì¶œ', 'ìë™ì°¨ ë‹´ë³´ ëŒ€ì¶œ ë‚´ì°¨ë¡œ', 'ì†Œì•¡ë¡  ì‹ ìš©ëŒ€ì¶œ', 'í”ŒëŸ¬ìŠ¤ë¡ ', 'íƒ‘ì—…ë¡ '], horizontal=True)
st.text('\n')

opt_gender = st.radio(
    r'''$\textsf{\large âœ… STEP2. ë¬¸êµ¬ë¥¼ ìƒì„±í•˜ë ¤ëŠ” íƒ€ê²Ÿì˜ ì„±ë³„ì„ ì„ íƒí•´ì£¼ì„¸ìš”}$''',['ë‚¨ì','ì—¬ì','ë¬´ê´€'], horizontal=True)
st.text('\n')

opt_age = st.radio(
    r'''$\textsf{\large âœ… STEP3. ë¬¸êµ¬ë¥¼ ìƒì„±í•˜ë ¤ëŠ” íƒ€ê²Ÿì˜ ì—°ë ¹ëŒ€ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”}$''',['20ëŒ€','30ëŒ€','40ëŒ€', '50ëŒ€ ì´ìƒ','ë¬´ê´€'], horizontal=True)
st.text('\n')

opt_job = st.text_input(r'''$\textsf{\large âœ… STEP4. ë¬¸êµ¬ë¥¼ ìƒì„±í•˜ë ¤ëŠ” íƒ€ê²Ÿì˜ ì§ì—…ì„ ì…ë ¥í•´ì£¼ì„¸ìš”(ex.ì§ì¥ì¸, ëŒ€í•™ìƒ, ì£¼ë¶€ ë“±)}$''','')
st.text('\n')

# ë¹ˆê°’ì¼ ê²½ìš° ì²˜ë¦¬
if opt_job == '' :
    opt_job = 'ìƒê´€ì—†ìŒ'

opt_style = st.radio(
    r'''$\textsf{\large âœ… STEP5. ì›í•˜ëŠ” ë¬¸êµ¬ì˜ ìŠ¤íƒ€ì¼ì„ ì„ íƒí•´ì£¼ì„¸ìš”}$''',
    [f'''ëŒ€ì¶œì´ë™ì„œë¹„ìŠ¤ë¡œ {opt_prod} ê°ˆì•„íƒ€ë©´ ê¸ˆë¦¬ëŠ” ë‚®ì•„ì§€ê³  í•œë„ëŠ” ë†’ì•„ì§ˆ ìˆ˜ ìˆì–´ìš”.''',
     'ì²« ë‹¬ ì´ì ìµœëŒ€ 50ë§Œì›ì˜ ê¸°íšŒ! ë§ˆì´ë„ˆìŠ¤ í†µì¥ì€ 3ë§Œì›ì„ ë“œë ¤ìš”!',
     f'''[KBìºí”¼íƒˆ] OOOë‹˜ {opt_prod} ê°ˆì•„íƒ€ë©´ ìš°ëŒ€ê¸ˆë¦¬ ìµœê³  ì—°0%p ì¸í•˜ ê°€ëŠ¥í•´ìš”!''',
     f'''ì¶•í•˜í•©ë‹ˆë‹¤ğŸ‰ğŸ‰ {opt_prod} ê¸ˆë¦¬ ì¸í•˜ ëŒ€ìƒìë¡œ ì„ ì •ë˜ì…¨ìŠµë‹ˆë‹¤!''',
     'ì—†ìŒ'], horizontal=False)
st.text('\n')

opt_etc = st.text_input(r'''$\textsf{\large âœ… STEP6. ìœ„ ë‚´ìš© ì™¸ì— ë¬¸êµ¬ì— ì¶”ê°€í•˜ê³  ì‹¶ì€ ë‚´ìš©ì„ ì…ë ¥í•´ì£¼ì„¸ìš” (ex.ë´„ì˜ ë¶„ìœ„ê¸°ì— ë§ì¶° ì‘ì„±í•´ì¤˜, 'ê¸ˆë¦¬'ë¼ëŠ” ë‹¨ì–´ë¥¼ í¬í•¨í•´ì¤˜)}$''','')
st.text('\n')

# llm temperature ì„¤ì • ê¸°ëŠ¥
st.write(r'''$\textsf{\normalsize âœ… STEP7. ìƒì„±í˜• AIì˜ ììœ ë„ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”}$''')
opt_temp = st.slider(r'''$\textsf{\small\textbf {â€» ììœ ë„ê°€ 1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ìƒì„±í˜• AIê°€ ë‹¤ì–‘í•œ ë¬¸êµ¬ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.}}$''', 0.0, 1.0, 0.5, step = 0.1, format="%.1f")
print('ì„ íƒëœ temperature : ',opt_temp)
st.text('\n')


# Retriever ê²€ìƒ‰ ê²°ê³¼
query = f"""{opt_prod}ì— ëŒ€í•´ ì•Œë ¤ì¤˜"""
docs = retriever.get_relevant_documents(query) # ê²€ìƒ‰ê²°ê³¼ ì €ì¥
# print(docs[0].page_content)

# LLM ëª¨ë¸ ìƒì„±
chat_model = ChatOpenAI(model = 'gpt-3.5-turbo-0125', temperature = opt_temp)

# gpt prompt
# í•œê¸€
# gpt_role_k = f"""
# system_role
# - ë‹¹ì‹ ì€ ê¸ˆìœµ ë§ˆì¼€íŒ… ë¶„ì•¼ì— ëŒ€í•´ í’ë¶€í•œ ê²½í—˜ê³¼ ì „ë¬¸ì§€ì‹ì„ ë³´ìœ í•˜ê³  ìˆëŠ” ì „ë¬¸ê°€ì´ë©°, ëŒ€í•œë¯¼êµ­ì˜ ê¸ˆìœµíšŒì‚¬ì¸ KBìºí”¼íƒˆì˜ ê¸ˆìœµ ìƒí’ˆ íŒë§¤ í™œì„±í™”ë¥¼ ìœ„í•´ ë§ˆì¼€íŒ… ë¬¸ìë©”ì‹œì§€ ì‘ì„±í•´ì•¼í•©ë‹ˆë‹¤.
# - ë§ˆì¼€íŒ… í•˜ë ¤ëŠ” KBìºí”¼íƒˆ ê¸ˆìœµ ìƒí’ˆì€ '{opt_prod}'ì´ë©°, ìƒí’ˆì— ëŒ€í•œ ì •ë³´ëŠ” ë‹¤ìŒ ë‚´ìš©ì„ ì°¸ê³ í•´ì£¼ì„¸ìš” : {docs}
# - ë§ˆì¼€íŒ… íƒ€ê²Ÿì˜ ì„±ë³„ì€ '{opt_gender}', ì—°ë ¹ëŒ€ëŠ” '{opt_age}', ì§ì—…ì€ '{opt_job}'ì…ë‹ˆë‹¤.
# - ë˜í•œ ë§ˆì¼€íŒ… ë¬¸êµ¬ ìƒì„± ì‹œ ì¶”ê°€ë¡œ ê³ ë ¤í•´ì•¼ í•  ì‚¬í•­ì€ '{opt_etc}'ì…ë‹ˆë‹¤.
# - ë‹¤ìŒ ë¬¸ìë©”ì‹œì§€ ì˜ˆì‹œë¥¼ ì°¸ê³ í•´ì„œ ì‘ì„±í•´ì£¼ì„¸ìš”. 'ëŒ€ì¶œì´ë™ì„œë¹„ìŠ¤ë¡œ ì‹ ìš©ëŒ€ì¶œ ê°ˆì•„íƒ€ë©´ ê¸ˆë¦¬ëŠ” ë‚®ì•„ì§€ê³  í•œë„ëŠ” ë†’ì•„ì§ˆ ìˆ˜ ìˆì–´ìš”.', 'ì²« ë‹¬ ì´ì ìµœëŒ€ 50ë§Œì›ì˜ ê¸°íšŒ! ë§ˆì´ë„ˆìŠ¤ í†µì¥ì€ 3ë§Œì›ì„ ë“œë ¤ìš”!'

# human_role
# - ë‹¤ì–‘í•œ ì–´íœ˜ì™€ ìì—°ìŠ¤ëŸ¬ìš´ í‘œí˜„ì„ ì‚¬ìš©í•˜ê³ , ë§ˆì¼€íŒ… íƒ€ê²Ÿì˜ íŠ¹ì„±ê³¼ ìƒí’ˆ ì •ë³´ë¥¼ ê³ ë ¤í•˜ì—¬ 5ê°œì˜ ë§ˆì¼€íŒ… ë¬¸êµ¬ë¥¼ ì‘ì„±í•´ì£¼ì‹­ì‹œì˜¤
# - ê° ë¬¸êµ¬ëŠ” 50ì ì´ë‚´ë¡œ ì‘ì„±í•´ì£¼ì‹œê³ , 5ê°œì˜ ë¬¸êµ¬ë¥¼ êµ¬ë¶„í•  ìˆ˜ ìˆë„ë¡ ê° ë¬¸êµ¬ ì•ì— 1~5ê¹Œì§€ì˜ ìˆ«ìë¥¼ ê¸°ì¬í•´ì£¼ì„¸ìš”.
# - ë‚´ìš©ì´ ì¤‘ë³µë˜ì§€ ì•Šê³ , ë°˜ë³µì ì¸ ë¬¸ì¥ì´ ìƒê¸°ì§€ ì•Šë„ë¡ ìì—°ìŠ¤ëŸ¬ìš´ ê¸€ì„ ì‘ì„±í•´ì£¼ì‹­ì‹œì˜¤.
# - ë§ˆì¼€íŒ… ë¬¸êµ¬ì— 'KBìºí”¼íƒˆ'ì´ë¼ëŠ” ë‹¨ì–´ë¥¼ ë°˜ë“œì‹œ í¬í•¨í•´ì£¼ì‹­ì‹œì˜¤.
# """


# system ì—­í•  ë¶€ì—¬
system_role = f"""
- You are an expert with extensive experience and expertise in the field of financial marketing, and you must write marketing text messages to promote sales of financial products for KB Capital, a financial company in Korea.
- The KB Capital's financial product you wish to market is '{opt_prod}', and for information on the product, please refer to the following: '{docs[0].page_content}'.
- The marketing target's gender is '{opt_gender}', age group is '{opt_age}', and occupation is '{opt_job}'.
"""

# opt_style 'ì—†ìŒ', opt_etc ë¹ˆê°’ì¼ ê²½ìš° system roleì—ì„œ ì œì™¸
if opt_etc != '':
    system_role = system_role+ f"""- Additionally, an additional consideration when creating marketing copy is '{opt_etc}'."""

if opt_style != 'ì—†ìŒ' :
    system_role = system_role+ f"""- Please refer to the following text sample messages when writing. '{opt_style}'"""


# human role 
human_role = f"""
- Please use a variety of vocabulary and natural expressions, and write five marketing phrases considering the characteristics of your marketing target and product information.
- Please write each phrase within 50 characters, and write a number from 1 to 5 in front of each phrase to distinguish between the 5 phrases.
- To distinguish between the five phrases, please write a number from 1 to 5 in front of each phrase.
- Please answer in Korean and write naturally to avoid duplication of content and repetitive sentences.
- Please be sure to include the word â€˜KBìºí”¼íƒˆâ€™ in your marketing text.
"""


messages = [ SystemMessage(content=system_role),
            HumanMessage(content=human_role)
]

print('prompt messages : \n', messages)
st.text('\n')

# ë‹µë³€ ë©”ì‹œì§€ ë…¸ì¶œ
if st.button('ë§ˆì¼€íŒ… ë¬¸êµ¬ ìƒì„±í•˜ê¸° ğŸ“‹', type= 'primary') : #type ì˜µì…˜ìœ¼ë¡œ ë²„íŠ¼ ìƒ‰ìƒ ë¹¨ê°•ìƒ‰ìœ¼ë¡œ ì„¤ì •
    with st.spinner('ë¬¸êµ¬ ìƒì„± ì¤‘...ğŸ¤–') :
        # chat_gpt ë‹µë³€ ìƒì„±
        completion = chat_model.invoke(messages)
        print(completion, '\n')

        # gptê°€ ë‹µë³€í•œ ë‚´ìš©ì„ ë³€ìˆ˜ì— ì €ì¥
        assistant_message = completion.content
        print(assistant_message)
        st.success(f'''ChatGPTê°€ ìƒì„±í•œ ë¬¸êµ¬ì…ë‹ˆë‹¤. ë‹¤ë¥¸ ë¬¸êµ¬ë¥¼ ë³´ê³  ì‹¶ìœ¼ì‹œë©´,
                   \n 'ë§ˆì¼€íŒ… ë¬¸êµ¬ ìƒì„±í•˜ê¸°'ë²„íŠ¼ì„ ë‹¤ì‹œ í•œë²ˆ ëˆŒëŸ¬ì£¼ì„¸ìš”!
                   \n \n \n P.S. ì°¸ê³ ë¡œ ë‹¤ìŒ ìƒí’ˆ ì •ë³´ë¥¼ ì°¸ê³ í•˜ì—¬ ë¬¸êµ¬ë¥¼ ì‘ì„±í–ˆì–´ìš”ğŸ˜
                   \n  {docs[0].page_content}
                   ''')
        st.success(assistant_message)

